# Scene Planner Implementation Prompt

You are tasked with implementing the Scene Planner module (Module 4, Phase 3) for an AI music video generation pipeline. Your primary challenge is to transform a user's simple creative prompt (50-500 characters, like "cyberpunk city at night with neon lights") into a comprehensive, director-informed prompt that will guide an LLM (GPT-4o or Claude 3.5 Sonnet) to generate professional scene plans. The Scene Planner must receive the AudioAnalysis output from Module 3 (containing BPM, beat timestamps, song structure, lyrics, mood, and clip boundaries) along with the user's creative prompt, then synthesize these inputs with the extensive director knowledge base (`scene_planner_director_knowledge.md`) to create detailed, actionable prompts for the LLM. The director knowledge base contains professional music video directing principles including visual pacing & rhythm (matching visuals to musical structure), color palette guidelines, camera movement techniques, transition styles, lighting techniques, cinematography principles, character planning, scene planning, storytelling modes, and genre-specific conventions. Your implementation must intelligently extract relevant director knowledge based on the audio analysis (mood, BPM, energy level, song structure) and user prompt, then construct a system prompt that instructs the LLM to apply these principles while respecting the user's creative vision.

The core implementation challenge lies in prompt engineering: you need to build a prompt synthesis system that takes the user's high-level creative vision and enriches it with appropriate director knowledge without overwhelming the LLM or losing the user's intent. For example, if a user provides "lonely walk through empty streets at night" and the audio analysis shows a calm mood (BPM <90, low energy), your system should extract relevant knowledge about calm mood color palettes (muted, desaturated colors), low energy camera movements (static shots, slow zooms, wide shots), appropriate lighting (soft, natural, slightly dim), and transition styles (fade for low energy sections). The synthesized prompt should explicitly instruct the LLM to: (1) maintain the user's core concept (lonely walk, empty streets, night), (2) apply director knowledge for mood/energy matching (calm = muted colors, slow camera, soft lighting), (3) generate clip scripts aligned to the provided clip boundaries from audio analysis, (4) create consistent characters and scenes, (5) plan transitions based on beat intensity, and (6) output a valid ScenePlan JSON structure. The prompt must be structured hierarchically: start with the director knowledge context (relevant sections based on audio analysis), then provide the user's creative prompt as the core vision, then include the audio analysis data (BPM, structure, lyrics, clip boundaries) as constraints, and finally specify the exact JSON output format required.

Your implementation should follow the PRD specifications in `PRD_scene_planner.md`, which defines the module structure including `planner.py` (core orchestration), `llm_client.py` (LLM API integration), `director_knowledge.py` (knowledge base loader), `script_generator.py` (clip script generation), `transition_planner.py` (transition planning), `style_analyzer.py` (consistency checking), and `validator.py` (output validation). The key file to focus on is `llm_client.py`, where you'll implement the `generate_scene_plan` function that constructs the final LLM prompt. This function should: (1) load director knowledge from `director_knowledge.py`, (2) extract relevant sections based on audio mood/energy/BPM (e.g., if energetic mood → include energetic color palettes, high energy camera movements, hard cut transitions), (3) format the user prompt as the creative vision anchor, (4) structure the audio context (song structure, lyrics, clip boundaries) as constraints, (5) explicitly instruct the LLM to apply director knowledge while maintaining user intent, and (6) request JSON output matching the ScenePlan Pydantic model. The prompt should be explicit and directive—tell the LLM exactly how to apply director knowledge (e.g., "Use muted, desaturated colors from the calm mood palette" rather than just "apply color guidelines"). Include examples of good clip scripts in the prompt to guide the LLM's output quality, and ensure the prompt emphasizes consistency (same character appearance, same scene lighting, same color palette per location) across all generated clips.

